#!/usr/bin/env node
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";

// GLM API ì„¤ì •
interface GlmConfig {
  apiKey: string;
  apiBase: string;
  model: string;
  thinkingMode: "interleaved" | "preserved" | "turn-level" | "none";
}

// ì—­í•  ì •ì˜
const ROLES = {
  analyst: {
    name: "Analyst",
    emoji: "ğŸ”",
    systemPrompt: `ë‹¹ì‹ ì€ ì‹¬ì¸µ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë‚´ìš©ì„ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ì—¬:
- í•µì‹¬ ìš”ì†Œì™€ êµ¬ì¡° íŒŒì•…
- íŒ¨í„´ê³¼ ê´€ê³„ ì‹ë³„
- ì ì¬ì  ë¬¸ì œì  ë°œê²¬
- ê°œì„  ê¸°íšŒ ë„ì¶œ
ë¶„ì„ ê²°ê³¼ë¥¼ ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”.`
  },
  reviewer: {
    name: "Reviewer",
    emoji: "ğŸ“‹",
    systemPrompt: `ë‹¹ì‹ ì€ ì½”ë“œ/ë¬¸ì„œ ê²€í†  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë‚´ìš©ì„ ê²€í† í•˜ì—¬:
- í’ˆì§ˆ ë° ì™„ì„±ë„ í‰ê°€
- ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì¤€ìˆ˜ ì—¬ë¶€
- ê°€ë…ì„± ë° ìœ ì§€ë³´ìˆ˜ì„±
- ë¬¸ì„œí™” ìˆ˜ì¤€
êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆê³¼ í•¨ê»˜ ê²€í†  ê²°ê³¼ë¥¼ ì œì‹œí•˜ì„¸ìš”.`
  },
  optimizer: {
    name: "Optimizer",
    emoji: "âš¡",
    systemPrompt: `ë‹¹ì‹ ì€ ì„±ëŠ¥ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë‚´ìš©ì„ ìµœì í™” ê´€ì ì—ì„œ:
- ì„±ëŠ¥ ë³‘ëª©ì  ì‹ë³„
- ë¦¬ì†ŒìŠ¤ ì‚¬ìš© íš¨ìœ¨ì„±
- ì•Œê³ ë¦¬ì¦˜/ë¡œì§ ê°œì„ ì 
- í™•ì¥ì„± ê³ ë ¤ì‚¬í•­
ì‹¤í–‰ ê°€ëŠ¥í•œ ìµœì í™” ë°©ì•ˆì„ ìš°ì„ ìˆœìœ„ì™€ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”.`
  },
  security: {
    name: "Security",
    emoji: "ğŸ”’",
    systemPrompt: `ë‹¹ì‹ ì€ ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë‚´ìš©ì„ ë³´ì•ˆ ê´€ì ì—ì„œ:
- ì ì¬ì  ì·¨ì•½ì  ì‹ë³„ (OWASP Top 10 ë“±)
- ì¸ì¦/ì¸ê°€ ê²€í† 
- ë°ì´í„° ë³´í˜¸ ë° ì•”í˜¸í™”
- ì…ë ¥ ê²€ì¦ ë° ì¶œë ¥ ì¸ì½”ë”©
ìœ„í—˜ ìˆ˜ì¤€ê³¼ í•¨ê»˜ êµ¬ì²´ì ì¸ ë³´ì•ˆ ê¶Œì¥ì‚¬í•­ì„ ì œì‹œí•˜ì„¸ìš”.`
  }
} as const;

type RoleKey = keyof typeof ROLES;

// ì„¤ì • ë¡œë“œ (í™˜ê²½ë³€ìˆ˜ì—ì„œ)
function loadConfig(): GlmConfig {
  return {
    apiKey: process.env.GLM_API_KEY || "",
    apiBase: process.env.GLM_API_BASE || "https://api.z.ai/api/paas/v4",
    model: process.env.GLM_MODEL || "glm-4.7",
    thinkingMode: (process.env.GLM_THINKING_MODE as GlmConfig["thinkingMode"]) || "interleaved"
  };
}

// GLM API í˜¸ì¶œ
async function callGlmApi(
  config: GlmConfig,
  systemPrompt: string,
  userMessage: string,
  options?: { temperature?: number; maxTokens?: number }
): Promise<string> {
  const response = await fetch(`${config.apiBase}/chat/completions`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${config.apiKey}`
    },
    body: JSON.stringify({
      model: config.model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userMessage }
      ],
      temperature: options?.temperature ?? 0.7,
      max_tokens: options?.maxTokens ?? 4096,
      thinking: config.thinkingMode !== "none" ? {
        mode: config.thinkingMode
      } : undefined
    })
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`GLM API error: ${response.status} - ${error}`);
  }

  const data = await response.json() as {
    choices: Array<{ message: { content: string } }>;
  };

  return data.choices[0]?.message?.content || "";
}

// ë³‘ë ¬ GLM í˜¸ì¶œ (ì•™ìƒë¸”)
async function callGlmParallel(
  config: GlmConfig,
  userMessage: string,
  roles: RoleKey[]
): Promise<Record<RoleKey, string>> {
  const results: Partial<Record<RoleKey, string>> = {};

  const promises = roles.map(async (roleKey) => {
    const role = ROLES[roleKey];
    try {
      const response = await callGlmApi(config, role.systemPrompt, userMessage);
      results[roleKey] = response;
    } catch (error) {
      results[roleKey] = `[ì˜¤ë¥˜] ${role.name} ë¶„ì„ ì‹¤íŒ¨: ${error instanceof Error ? error.message : String(error)}`;
    }
  });

  await Promise.all(promises);
  return results as Record<RoleKey, string>;
}

// ì•™ìƒë¸” ê²°ê³¼ ì¢…í•©
function synthesizeResults(results: Record<RoleKey, string>): string {
  const sections: string[] = [];

  for (const [roleKey, content] of Object.entries(results)) {
    const role = ROLES[roleKey as RoleKey];
    sections.push(`## ${role.emoji} ${role.name} ë¶„ì„\n\n${content}`);
  }

  return sections.join("\n\n---\n\n");
}

// MCP ì„œë²„ ìƒì„±
const server = new McpServer({
  name: "glm-ensemble",
  version: "0.1.0"
});

// Tool: glm_chat - ë‹¨ì¼ GLM í˜¸ì¶œ
server.tool(
  "glm_chat",
  "GLM-4.7ì— ë‹¨ì¼ ì§ˆì˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤",
  {
    message: z.string().describe("GLMì— ë³´ë‚¼ ë©”ì‹œì§€"),
    role: z.enum(["analyst", "reviewer", "optimizer", "security"]).optional()
      .describe("ì‚¬ìš©í•  ì—­í•  (ê¸°ë³¸: ì¼ë°˜ ëŒ€í™”)"),
    temperature: z.number().min(0).max(2).optional()
      .describe("ì‘ë‹µì˜ ì°½ì˜ì„± (0~2, ê¸°ë³¸: 0.7)"),
    maxTokens: z.number().positive().optional()
      .describe("ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸: 4096)")
  },
  async ({ message, role, temperature, maxTokens }) => {
    const config = loadConfig();

    if (!config.apiKey) {
      return {
        content: [{ type: "text", text: "âŒ GLM_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ~/.claude/glm-ensemble.local.mdë¥¼ í™•ì¸í•˜ì„¸ìš”." }]
      };
    }

    const systemPrompt = role ? ROLES[role].systemPrompt : "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.";

    try {
      const response = await callGlmApi(config, systemPrompt, message, { temperature, maxTokens });
      const roleInfo = role ? `${ROLES[role].emoji} **${ROLES[role].name}**\n\n` : "";

      return {
        content: [{ type: "text", text: `${roleInfo}${response}` }]
      };
    } catch (error) {
      return {
        content: [{ type: "text", text: `âŒ GLM í˜¸ì¶œ ì‹¤íŒ¨: ${error instanceof Error ? error.message : String(error)}` }]
      };
    }
  }
);

// Tool: glm_ensemble - ë³‘ë ¬ ë©€í‹°ì—ì´ì „íŠ¸ í˜¸ì¶œ
server.tool(
  "glm_ensemble",
  "4ê°œ ì—­í• (ë¶„ì„/ê²€í† /ìµœì í™”/ë³´ì•ˆ)ë¡œ ë³‘ë ¬ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤",
  {
    message: z.string().describe("ë¶„ì„í•  ë‚´ìš© ë˜ëŠ” ì§ˆë¬¸"),
    roles: z.array(z.enum(["analyst", "reviewer", "optimizer", "security"])).optional()
      .describe("ì‚¬ìš©í•  ì—­í• ë“¤ (ê¸°ë³¸: 4ê°œ ì „ë¶€)")
  },
  async ({ message, roles }) => {
    const config = loadConfig();

    if (!config.apiKey) {
      return {
        content: [{ type: "text", text: "âŒ GLM_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ~/.claude/glm-ensemble.local.mdë¥¼ í™•ì¸í•˜ì„¸ìš”." }]
      };
    }

    const selectedRoles: RoleKey[] = roles || ["analyst", "reviewer", "optimizer", "security"];

    try {
      const results = await callGlmParallel(config, message, selectedRoles);
      const synthesis = synthesizeResults(results);

      return {
        content: [{
          type: "text",
          text: `# ğŸ¯ GLM ì•™ìƒë¸” ë¶„ì„ ê²°ê³¼\n\n${synthesis}\n\n---\n\n## ğŸ“Š ì¢…í•©\n\nìœ„ ${selectedRoles.length}ê°œ ê´€ì ì˜ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ìµœì ì˜ ì†”ë£¨ì…˜ì„ ë„ì¶œí•˜ì„¸ìš”.`
        }]
      };
    } catch (error) {
      return {
        content: [{ type: "text", text: `âŒ GLM ì•™ìƒë¸” í˜¸ì¶œ ì‹¤íŒ¨: ${error instanceof Error ? error.message : String(error)}` }]
      };
    }
  }
);

// Tool: glm_config - í˜„ì¬ ì„¤ì • í™•ì¸
server.tool(
  "glm_config",
  "í˜„ì¬ GLM ì„¤ì •ì„ í™•ì¸í•©ë‹ˆë‹¤",
  {},
  async () => {
    const config = loadConfig();

    const status = config.apiKey ? "âœ… ì„¤ì •ë¨" : "âŒ ë¯¸ì„¤ì •";
    const maskedKey = config.apiKey
      ? `${config.apiKey.slice(0, 8)}...${config.apiKey.slice(-4)}`
      : "(ì—†ìŒ)";

    const configInfo = `# GLM Ensemble ì„¤ì •

| í•­ëª© | ê°’ |
|------|-----|
| API Key | ${status} (${maskedKey}) |
| API Base | ${config.apiBase} |
| Model | ${config.model} |
| Thinking Mode | ${config.thinkingMode} |

## ì—­í•  ëª©ë¡

| ì—­í•  | ì„¤ëª… |
|------|------|
| ğŸ” Analyst | ì‹¬ì¸µ ë¶„ì„ |
| ğŸ“‹ Reviewer | ì½”ë“œ/ë¬¸ì„œ ê²€í†  |
| âš¡ Optimizer | ì„±ëŠ¥ ìµœì í™” |
| ğŸ”’ Security | ë³´ì•ˆ ê²€í†  |

## ì„¤ì • ë°©ë²•

\`~/.claude/glm-ensemble.local.md\` íŒŒì¼ì— ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì„¤ì •:

\`\`\`markdown
# GLM Ensemble ì„¤ì •

## API ì„¤ì •
- GLM_API_KEY: your-api-key
- GLM_API_BASE: https://api.z.ai/api/paas/v4
- GLM_MODEL: glm-4.7
- GLM_THINKING_MODE: interleaved
\`\`\``;

    return {
      content: [{ type: "text", text: configInfo }]
    };
  }
);

// ì„œë²„ ì‹œì‘
async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error("GLM Ensemble MCP Server started");
}

main().catch(console.error);
